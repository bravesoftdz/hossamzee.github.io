<!DOCTYPE html>
<html lang="ar">
<head>

	<meta charset="utf-8" />

	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta http-equiv="Content-Language" content="ar">
	<meta name="viewport" content="initial-scale=1, maximum-scale=1">

	<link rel="stylesheet" type="text/css" href="css/jaw.css">
	<link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.2/styles/default.min.css">

	<title>حسام الزغيبي - بناء زاحف للويب و استقاء و معالجة المعلومة</title>
</head>
<body>

	<div class="container">

		<header>
			<h1>حسام الزغيبي</h1>
			<p>مطوّر لتطبيقات الويب و الجوّال.</p>
		</header>

		<nav>
			<ul>
				<li><a href="index.html">الأولى</a></li>
				<li><a href="about.html">نبذة</a></li>
			</ul>
		</nav>

		<article>
			<div class="heading">
				<h1>بناء زاحف للويب و استقاء و معالجة المعلومة</h1>
				<h4 class="date">18 سبتمبر 2014، 12:36 صباحاً</h4>
			</div>
			<p>
				موضوع المقالة -عزيزي القارئ- قديمٌ جديد، لكنّي أستخدمه بين الفينة و الأخرى، و هو زاحف الويب Web Crawler، الفكرة من هذا الزاحف -قصدتها بالمعنى اللبق- أن يصل إلى عنوان ويب، ثم يقوم بتحميل المحتوى، ثم معالجته، هذه الثلاث خطوات هي التي تقيم زاحف الويب، و من خلالها، سأبني وإيّاك زاحفاً بسيطاً للويب بلغة PHP وقد نتعمّق في الأمر لاحقاً.
			</p>

			<p>
				قبل أن تبني زاحف ويبٍ إلى موقع ما، اسأل نفسك: "هل أحتاج إلى زاحف ويب إلى هذا الموقع؟"، ولكي تجيب على هذا لسؤال، لابدّ و أن تعرف ما إذا كان الموقع المُراد يقدّم واجهة لبرمجة التطبيق API (أو تغذيات RSS) أم لا، وكذلك، هل يسمح هذا الموقع بأن يتم الزحف إليه أم لا؟
			</p>

			<p>
				أمّا بشأن المسألة الأولى، فإذا كان الموقع يوفّر الواجهة البرمجية للتطبيق API أو تغذيات RSS، فهذا يعني أن الموقع قد وفّر لنا البيانات التي نريد، بل، وخفّف علينا مسألة معالجة البيانات المستقاة، و أمّا المسألة الثانية، فسماح الموقع من عدمه، هذا، من باب احترام حقوق الملكية الفكرية و الذوق العام، أمّا إذا كان الأمر خلاف ما سبق، فبناء زاحف الويب سيكون أمراً مناسباً.
			</p>

			<p>
				لنبدأ ببناء زاحف الويب و لنختار موقعاً مناسباً، ما رأيك في موقع naq.sh؟ موقع للنقاش العربيّ؟ مناسب؟ أظنّه كذلك، إذاً سنبني زاحفاً يجلب آخر المقالات المطروحة في تصنيف البرمجة، ثم، نعرضها بشكل مختلف، و نشير إلى المصدر. أفترض أنّ الأمر سيكون ممتعاً.
			</p>

			<p class="note">
				سلوك وَ وظائف زاحف الويب يحدّدها تماماً الرابط المُراد الزحف إليه، لابدّ من فهم الرابط و محتواه فهماً صحيحاً.
			</p>

			<div class="heading">
				<h3>تعيين الثوابت (Constants)</h3>
			</div>

			<p>
				أبرز الثوابت، ثابت الوقت الأقصى لتنفيذ السكربت، و هو بالثواني، و الهدف منه تقييد مدّة تنفيذ السكربت، لكي لا يستنزف موارد الجهاز، أيضاً، أضفت ثابتاً آخر لإعطاء معلومة معيّنة للموقع الذي ننوي الزحف إليه، من باب التعريف بالسكربت و إيضاحاً بأن النيّة سليمة و حسنة. و أخيراً، أضفت ثابتاً يحوي الرابط المًراد الزحف إليه.
			</p>

<pre>
<code class="php">define("TIMIE_LIMIT", 30); // The maximum execution time in seconds.
define("USER_AGENT", "Hossamzee Bot"); // User agent, from the ethical point of view.
define("URL", "http://naq.sh/topic/4"); // URL to be crawled.
define("BASE_URL", "http://naq.sh"); // Base URL anyway.
</code>
</pre>

			<div class="heading">
				<h3>تعيين السلوك (Behavior)</h3>
			</div>

			<p>
				في حالة زاحف الويب الذي نبنيه، سيكون لدينا 3 خطوات فقط، الأولى: الوصول إلى موقع الويب و استقاء المعلومة، الثانية: معالجة المعلومات الراجعة من الموقع، و الثالثة و الأخيرة: تمثيل المعلومات بطريقة مختلفة، و الأخيرة تعتبر اختياريّة لأنّه قد لا يستدعي الأمر تمثيل البيانات للمستخدم، بل قد يُكتفى بحفظ البيانات في قاعدة البيانات أو في ملف نصّي، أو ربما يُتّخذ قرار ما، و هكذا.
			</p>

<pre>
<code class="php">// 1. Get the contents of the URL.
$contents = crawler_get_contents(URL);

// 2. Proccess whatever you need with the contents.
$data = crawler_process_contents($contents);

// 3. Represent the processing output in the way you like (optional).
echo crawler_represent_data($data);
</code>
</pre>

			<div class="heading">
				<h3>الوظيفة الأولى: استقاء المعلومة من الرابط.</h3>
			</div>

<pre>
<code class="php">// Returns $contents fetched from a given $url.
function crawler_get_contents($url)
{
	$curl_handler = curl_init();

	// Set some options.
	curl_setopt($curl_handler, CURLOPT_URL, $url);
	curl_setopt($curl_handler, CURLOPT_HEADER, false);
	curl_setopt($curl_handler, CURLOPT_RETURNTRANSFER, true);
	curl_setopt($curl_handler, CURLOPT_USERAGENT, USER_AGENT);

	// Execute the CURLing.
	$contents = curl_exec($curl_handler);

	// Close the connection, or the handler.
	curl_close($curl_handler);

	return $contents;
}
</code>
</pre>

			<div class="heading">
				<h3>الوظيفة الثانية: معالجة المعلومة.</h3>
			</div>

<pre>
<code class="php">// Returns $data processed from given $contents.
function crawler_process_contents($contents)
{
	// Reach the latest articles and their associated URLs.
	$articles = [];

    // Get the matches.
    // --------------------------(1-)--(2-)-----(3-) --------(4-)-------
    preg_match_all('/&lt;5>&lt;a href="(.*)">(.*)&lt;\/a>(.*)&lt;a href="(.*)" target="_blank">/isU', $contents, $matches);

    // Get the count of the found articles, in our case, it should be 20.
    $found_articles_count = count($matches[0]);

    for ($i=0; $i&lt;$found_articles_count; $i++)
    {
    	$article_title = $matches[2][$i];
    	$article_internal_link = $matches[1][$i];
    	$article_external_link = $matches[4][$i];

    	$articles[] = [
    		"title" => $article_title,
    		"internal_link" => BASE_URL . $article_internal_link,
    		"external_link" => $article_external_link
    	];
    }

	return $articles;
}
</code>
</pre>

			<div class="heading">
				<h3>الوظيفة الثالثة: تمثيل المعلومة (اختياريّة).</h3>
			</div>

<pre>
<code class="php">// Returns a $representation for given $data.
function crawler_represent_data($data)
{
	$representation  = "&lt;!DOCTYPE HTML>&lt;html style='direction: rtl'>&lt;head>&lt;meta charset=\"utf-8\" />&lt;/head>&lt;body>";
	
	foreach ($data as $article)
	{
		$representation .= "&lt;div style='padding: 8px; border: 1px solid #ccc; margin-bottom: 8px;'>";
		$representation .= "&lt;b>$article[title]&lt;/b>&lt;br />";
		$representation .= "الرابط: &lt;a href='#'>$article[external_link]&lt;/a>, النقاش: &lt;a href='#'>$article[internal_link]&lt;/a>";
		$representation .= "&lt;/div>\n\n";
	}

	$representation .= "&lt;small>المحتوى من نقش.&lt;/small>";
	$representation .= "&lt;/body>&lt;/html>";

	return $representation;
}
</code>
</pre>

			<div class="heading">
				<h3>الكود كوحدةٍ واحدة.</h3>
			</div>

			<p>
				حاولت أن أكتب كوداً نظيفاً مفسّراً لذاته (<a href="http://en.wikipedia.org/wiki/Self-documenting">Self-documenting</a>) راجيّاً أن يكون مدخلاً مناسباً لك إلى زواحف الويب، تذكّر، أنّه بإمكانك الإطّلاع على كامل الكود من خلال هذا الرابط: <a href="https://gist.github.com/hossamzee/b6aab9514c6006bdfb64">https://gist.github.com/hossamzee/b6aab9514c6006bdfb64</a>.
			</p>

		</article>

		<footer>
			<p>
				بعض الحقوق محفوظة.
			</p>
			<p>
				<img src="http://hitwebcounter.com/counter/counter.php?page=5786797&style=0008&nbdigits=5&type=page&initCount=0" border="0" />
			</p>
		</footer>

	</div>

	<script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.2/highlight.min.js"></script>
	<script>hljs.initHighlightingOnLoad();</script>

</body>
</html>